{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = r'C:\\Users\\7153678\\Desktop\\AI\\src\\nlp\\data\\mnist'\n",
    "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
    "\n",
    "image_size = 28\n",
    "class_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (200000, 28, 28) and (200000,)\n",
      "valid: (10000, 28, 28) and (10000,)\n",
      "test: (10000, 28, 28) and (10000,)\n"
     ]
    }
   ],
   "source": [
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_data = save['train_data']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_data = save['valid_data']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_data = save['test_data']\n",
    "    test_labels = save['test_labels']\n",
    "    del save\n",
    "    \n",
    "print('train: {} and {}'.format(train_data.shape, train_labels.shape))\n",
    "print('valid: {} and {}'.format(valid_data.shape, valid_labels.shape))    \n",
    "print('test: {} and {}'.format(test_data.shape, test_labels.shape))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(data, labels):\n",
    "    new_data = data.reshape(-1, image_size**2)\n",
    "    new_label = (labels[:, None] == np.arange(class_num)).astype(np.float32)\n",
    "    return new_data, new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (200000, 784) and (200000, 10)\n",
      "valid: (10000, 784) and (10000, 10)\n",
      "test: (10000, 784) and (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels = reformat(train_data, train_labels)\n",
    "valid_data, valid_labels = reformat(valid_data, valid_labels)\n",
    "test_data, test_labels = reformat(test_data, test_labels)\n",
    "print('train: {} and {}'.format(train_data.shape, train_labels.shape))\n",
    "print('valid: {} and {}'.format(valid_data.shape, valid_labels.shape))    \n",
    "print('test: {} and {}'.format(test_data.shape, test_labels.shape))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Build model  block in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    \n",
    "    #imput dafa\n",
    "    tf_train_data = tf.constant(train_data[:train_subset, :])\n",
    "    tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "    tf_valid_data = tf.constant(valid_data)    \n",
    "    tf_test_data = tf.constant(test_data)\n",
    "    \n",
    "    #variables\n",
    "    weights = tf.Variable(tf.truncated_normal([image_size**2, class_num]))\n",
    "    biases = tf.Variable(tf.zeros(class_num))\n",
    "    \n",
    "    #computation\n",
    "    logits = tf.matmul(tf_train_data, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "    #optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    #predictions\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_data, weights)+biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_data, weights)+biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return 100.0*sum(np.argmax(predictions, 1)==np.argmax(labels, 1))/labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized!\n",
      "Train at step 0 with loss: 16.927234649658203\n",
      "Train accuracy: 7.67, valid accuracy: 11.18\n",
      "Train at step 50 with loss: 2.7983522415161133\n",
      "Train accuracy: 67.25, valid accuracy: 67.06\n",
      "Train at step 100 with loss: 2.3227155208587646\n",
      "Train accuracy: 71.9, valid accuracy: 71.38\n",
      "Train at step 150 with loss: 2.0675525665283203\n",
      "Train accuracy: 73.22, valid accuracy: 72.89\n",
      "Train at step 200 with loss: 1.8890845775604248\n",
      "Train accuracy: 74.35, valid accuracy: 73.65\n",
      "Train at step 250 with loss: 1.751396894454956\n",
      "Train accuracy: 74.74, valid accuracy: 74.16\n",
      "Train at step 300 with loss: 1.640235185623169\n",
      "Train accuracy: 75.17, valid accuracy: 74.44\n",
      "Train at step 350 with loss: 1.548066258430481\n",
      "Train accuracy: 75.58, valid accuracy: 74.66\n",
      "Train at step 400 with loss: 1.4702507257461548\n",
      "Train accuracy: 76.05, valid accuracy: 74.78\n",
      "Train at step 450 with loss: 1.4034371376037598\n",
      "Train accuracy: 76.47, valid accuracy: 74.92\n",
      "Train at step 500 with loss: 1.3451465368270874\n",
      "Train accuracy: 76.84, valid accuracy: 75.03\n",
      "Train at step 550 with loss: 1.2936192750930786\n",
      "Train accuracy: 77.15, valid accuracy: 75.13\n",
      "Train at step 600 with loss: 1.247593641281128\n",
      "Train accuracy: 77.39, valid accuracy: 75.28\n",
      "Train at step 650 with loss: 1.206130862236023\n",
      "Train accuracy: 77.64, valid accuracy: 75.41\n",
      "Train at step 700 with loss: 1.1685023307800293\n",
      "Train accuracy: 77.83, valid accuracy: 75.46\n",
      "Train at step 750 with loss: 1.134138822555542\n",
      "Train accuracy: 77.96, valid accuracy: 75.52\n",
      "Train at step 800 with loss: 1.1025906801223755\n",
      "Train accuracy: 78.27, valid accuracy: 75.69\n",
      "Test accuracy: 82.58\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as session:\n",
    "    # initailize\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized!')\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # excute compution\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "        if step%50 == 0:\n",
    "            train_accuracy = accuracy(predictions, train_labels[:train_subset, :])\n",
    "            valid_accuracy = accuracy(valid_prediction.eval(), valid_labels)\n",
    "            print('Train at step {} with loss: {}'.format(step, l))\n",
    "            print('Train accuracy: {}, valid accuracy: {}'.format(train_accuracy, valid_accuracy))\n",
    "            \n",
    "    print('Test accuracy: {}'.format(accuracy(test_prediction.eval(), test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # input, only train is with SGD\n",
    "    tf_train_data = tf.placeholder(tf.float32, shape=(batch_size, image_size**2))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, class_num))\n",
    "    tf_valid_data = tf.constant(valid_data)\n",
    "    tf_test_data = tf.constant(test_data)\n",
    "    \n",
    "    # variables\n",
    "    weights = tf.Variable(tf.truncated_normal([image_size**2, class_num]))\n",
    "    biases = tf.Variable(tf.zeros(class_num))\n",
    "    \n",
    "    # train compution\n",
    "    logits = tf.matmul(tf_train_data, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    # prediction\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_data, weights)+biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_data, weights)+biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 30001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initilazed\n",
      "Mini-batch train at step 0 with loss: 17.55832862854004\n",
      "Mini-batch train accuracy: 9.375, valid accuracy: 8.61\n",
      "Mini-batch train at step 500 with loss: 2.54551362991333\n",
      "Mini-batch train accuracy: 71.875, valid accuracy: 75.98\n",
      "Mini-batch train at step 1000 with loss: 1.5546658039093018\n",
      "Mini-batch train accuracy: 77.34375, valid accuracy: 77.17\n",
      "Mini-batch train at step 1500 with loss: 1.2392942905426025\n",
      "Mini-batch train accuracy: 80.46875, valid accuracy: 77.86\n",
      "Mini-batch train at step 2000 with loss: 0.8931864500045776\n",
      "Mini-batch train accuracy: 85.9375, valid accuracy: 78.65\n",
      "Mini-batch train at step 2500 with loss: 1.0539610385894775\n",
      "Mini-batch train accuracy: 73.4375, valid accuracy: 79.06\n",
      "Mini-batch train at step 3000 with loss: 1.2189171314239502\n",
      "Mini-batch train accuracy: 75.0, valid accuracy: 79.59\n",
      "Mini-batch train at step 3500 with loss: 0.8143807649612427\n",
      "Mini-batch train accuracy: 78.90625, valid accuracy: 79.32\n",
      "Mini-batch train at step 4000 with loss: 0.6500001549720764\n",
      "Mini-batch train accuracy: 83.59375, valid accuracy: 78.67\n",
      "Mini-batch train at step 4500 with loss: 0.8519778251647949\n",
      "Mini-batch train accuracy: 75.0, valid accuracy: 79.45\n",
      "Mini-batch train at step 5000 with loss: 0.8141782283782959\n",
      "Mini-batch train accuracy: 78.125, valid accuracy: 80.24\n",
      "Mini-batch train at step 5500 with loss: 0.7418191432952881\n",
      "Mini-batch train accuracy: 82.03125, valid accuracy: 79.86\n",
      "Mini-batch train at step 6000 with loss: 0.8203035593032837\n",
      "Mini-batch train accuracy: 80.46875, valid accuracy: 80.29\n",
      "Mini-batch train at step 6500 with loss: 0.5102294683456421\n",
      "Mini-batch train accuracy: 80.46875, valid accuracy: 80.49\n",
      "Mini-batch train at step 7000 with loss: 0.9772554039955139\n",
      "Mini-batch train accuracy: 78.90625, valid accuracy: 79.75\n",
      "Mini-batch train at step 7500 with loss: 0.7731378078460693\n",
      "Mini-batch train accuracy: 80.46875, valid accuracy: 81.08\n",
      "Mini-batch train at step 8000 with loss: 0.7668753266334534\n",
      "Mini-batch train accuracy: 80.46875, valid accuracy: 81.16\n",
      "Mini-batch train at step 8500 with loss: 0.7695080041885376\n",
      "Mini-batch train accuracy: 78.90625, valid accuracy: 81.17\n",
      "Mini-batch train at step 9000 with loss: 0.6747214794158936\n",
      "Mini-batch train accuracy: 85.15625, valid accuracy: 81.25\n",
      "Mini-batch train at step 9500 with loss: 0.6747294664382935\n",
      "Mini-batch train accuracy: 81.25, valid accuracy: 81.13\n",
      "Mini-batch train at step 10000 with loss: 0.8886744976043701\n",
      "Mini-batch train accuracy: 76.5625, valid accuracy: 81.55\n",
      "Mini-batch train at step 10500 with loss: 0.7476354241371155\n",
      "Mini-batch train accuracy: 82.8125, valid accuracy: 81.34\n",
      "Mini-batch train at step 11000 with loss: 0.6293487548828125\n",
      "Mini-batch train accuracy: 82.03125, valid accuracy: 81.83\n",
      "Mini-batch train at step 11500 with loss: 0.74198979139328\n",
      "Mini-batch train accuracy: 82.8125, valid accuracy: 81.48\n",
      "Mini-batch train at step 12000 with loss: 0.5310914516448975\n",
      "Mini-batch train accuracy: 84.375, valid accuracy: 81.77\n",
      "Mini-batch train at step 12500 with loss: 0.5739683508872986\n",
      "Mini-batch train accuracy: 81.25, valid accuracy: 81.59\n",
      "Mini-batch train at step 13000 with loss: 0.6174803972244263\n",
      "Mini-batch train accuracy: 82.8125, valid accuracy: 81.7\n",
      "Mini-batch train at step 13500 with loss: 0.6361168622970581\n",
      "Mini-batch train accuracy: 84.375, valid accuracy: 81.97\n",
      "Mini-batch train at step 14000 with loss: 0.7138166427612305\n",
      "Mini-batch train accuracy: 83.59375, valid accuracy: 81.68\n",
      "Mini-batch train at step 14500 with loss: 0.5039709210395813\n",
      "Mini-batch train accuracy: 86.71875, valid accuracy: 82.1\n",
      "Mini-batch train at step 15000 with loss: 0.7753888368606567\n",
      "Mini-batch train accuracy: 82.03125, valid accuracy: 81.98\n",
      "Mini-batch train at step 15500 with loss: 0.8343779444694519\n",
      "Mini-batch train accuracy: 78.125, valid accuracy: 82.26\n",
      "Mini-batch train at step 16000 with loss: 0.8250156044960022\n",
      "Mini-batch train accuracy: 78.90625, valid accuracy: 81.21\n",
      "Mini-batch train at step 16500 with loss: 0.7529851198196411\n",
      "Mini-batch train accuracy: 82.03125, valid accuracy: 81.81\n",
      "Mini-batch train at step 17000 with loss: 1.0128270387649536\n",
      "Mini-batch train accuracy: 78.90625, valid accuracy: 82.17\n",
      "Mini-batch train at step 17500 with loss: 0.7314625978469849\n",
      "Mini-batch train accuracy: 76.5625, valid accuracy: 81.75\n",
      "Mini-batch train at step 18000 with loss: 0.9056716561317444\n",
      "Mini-batch train accuracy: 71.875, valid accuracy: 81.74\n",
      "Mini-batch train at step 18500 with loss: 0.7254598140716553\n",
      "Mini-batch train accuracy: 78.90625, valid accuracy: 82.4\n",
      "Mini-batch train at step 19000 with loss: 0.7164255380630493\n",
      "Mini-batch train accuracy: 82.8125, valid accuracy: 81.34\n",
      "Mini-batch train at step 19500 with loss: 0.6480911374092102\n",
      "Mini-batch train accuracy: 83.59375, valid accuracy: 82.37\n",
      "Mini-batch train at step 20000 with loss: 0.6199069619178772\n",
      "Mini-batch train accuracy: 84.375, valid accuracy: 81.96\n",
      "Mini-batch train at step 20500 with loss: 0.5171382427215576\n",
      "Mini-batch train accuracy: 82.03125, valid accuracy: 82.2\n",
      "Mini-batch train at step 21000 with loss: 0.7108688354492188\n",
      "Mini-batch train accuracy: 84.375, valid accuracy: 81.94\n",
      "Mini-batch train at step 21500 with loss: 0.592866063117981\n",
      "Mini-batch train accuracy: 83.59375, valid accuracy: 82.37\n",
      "Mini-batch train at step 22000 with loss: 0.5027672052383423\n",
      "Mini-batch train accuracy: 85.9375, valid accuracy: 82.2\n",
      "Mini-batch train at step 22500 with loss: 0.5616627335548401\n",
      "Mini-batch train accuracy: 85.9375, valid accuracy: 82.08\n",
      "Mini-batch train at step 23000 with loss: 0.7501647472381592\n",
      "Mini-batch train accuracy: 76.5625, valid accuracy: 81.99\n",
      "Mini-batch train at step 23500 with loss: 0.6020761728286743\n",
      "Mini-batch train accuracy: 82.03125, valid accuracy: 82.24\n",
      "Mini-batch train at step 24000 with loss: 0.8608242273330688\n",
      "Mini-batch train accuracy: 82.03125, valid accuracy: 82.06\n",
      "Mini-batch train at step 24500 with loss: 0.6063889265060425\n",
      "Mini-batch train accuracy: 85.15625, valid accuracy: 82.06\n",
      "Mini-batch train at step 25000 with loss: 0.7111301422119141\n",
      "Mini-batch train accuracy: 79.6875, valid accuracy: 82.1\n",
      "Mini-batch train at step 25500 with loss: 0.5714229345321655\n",
      "Mini-batch train accuracy: 85.15625, valid accuracy: 82.62\n",
      "Mini-batch train at step 26000 with loss: 0.6038453578948975\n",
      "Mini-batch train accuracy: 85.9375, valid accuracy: 82.35\n",
      "Mini-batch train at step 26500 with loss: 0.4938214123249054\n",
      "Mini-batch train accuracy: 85.9375, valid accuracy: 82.6\n",
      "Mini-batch train at step 27000 with loss: 0.7253439426422119\n",
      "Mini-batch train accuracy: 81.25, valid accuracy: 82.66\n",
      "Mini-batch train at step 27500 with loss: 0.5873265862464905\n",
      "Mini-batch train accuracy: 80.46875, valid accuracy: 82.3\n",
      "Mini-batch train at step 28000 with loss: 0.5343105792999268\n",
      "Mini-batch train accuracy: 87.5, valid accuracy: 82.76\n",
      "Mini-batch train at step 28500 with loss: 0.4846891462802887\n",
      "Mini-batch train accuracy: 87.5, valid accuracy: 82.05\n",
      "Mini-batch train at step 29000 with loss: 0.7427193522453308\n",
      "Mini-batch train accuracy: 80.46875, valid accuracy: 82.21\n",
      "Mini-batch train at step 29500 with loss: 0.7560439109802246\n",
      "Mini-batch train accuracy: 80.46875, valid accuracy: 82.29\n",
      "Mini-batch train at step 30000 with loss: 0.8075751066207886\n",
      "Mini-batch train accuracy: 76.5625, valid accuracy: 81.91\n",
      "Mini-batch test accuarcy: 87.9\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initilazed')\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        offset = (step*batch_size)%(train_labels.shape[0]-batch_size)\n",
    "        # generate a mini-batch\n",
    "        batch_data = train_data[offset:(offset+batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "        \n",
    "        # dict to feed mini-batch\n",
    "        feed_dict = {tf_train_data: batch_data, tf_train_labels: batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        \n",
    "        # logging\n",
    "        if step % 500 == 0:\n",
    "            print('Mini-batch train at step {} with loss: {}'.format(step, l))\n",
    "            print('Mini-batch train accuracy: {}, valid accuracy: {}'.format(\n",
    "                 accuracy(predictions, batch_labels),\n",
    "                 accuracy(valid_prediction.eval(), valid_labels)))\n",
    "    print('Mini-batch test accuarcy: {}'.format(accuracy(test_prediction.eval(), test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Add Relu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "graph = tf.Graph()\n",
    "h1 = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # input, only train is with SGD\n",
    "    tf_train_data = tf.placeholder(tf.float32, shape=(batch_size, image_size**2))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, class_num))\n",
    "    tf_valid_data = tf.constant(valid_data)\n",
    "    tf_test_data = tf.constant(test_data)\n",
    "    \n",
    "    # variables\n",
    "    weights1 = tf.Variable(tf.truncated_normal([image_size**2, h1]))\n",
    "    biases1 = tf.Variable(tf.zeros(h1))  \n",
    "    weights2 = tf.Variable(tf.truncated_normal([h1, class_num]))\n",
    "    biases2 = tf.Variable(tf.zeros(class_num))  \n",
    "    \n",
    "    # train compution   \n",
    "    logits_1 = tf.matmul(tf_train_data, weights1) + biases1\n",
    "    relu_layer = tf.nn.relu(logits_1)\n",
    "    logits_2 = tf.matmul(relu_layer, weights2) + biases2\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels, logits=logits_2))\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    # prediction\n",
    "    train_prediction = tf.nn.softmax(logits_2)\n",
    "    \n",
    "    logits_1 = tf.matmul(tf_valid_data, weights1) + biases1\n",
    "    relu_layer = tf.nn.relu(logits_1)\n",
    "    logits_2 = tf.matmul(relu_layer, weights2) + biases2\n",
    "    valid_prediction = tf.nn.softmax(logits_2)\n",
    "\n",
    "    logits_1 = tf.matmul(tf_test_data, weights1) + biases1\n",
    "    relu_layer = tf.nn.relu(logits_1)\n",
    "    logits_2 = tf.matmul(relu_layer, weights2) + biases2\n",
    "    test_prediction = tf.nn.softmax(logits_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 30001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initilazed\n",
      "Mini-batch train at step 0 with loss: 353.59393310546875\n",
      "Mini-batch train accuracy: 10.15625, valid accuracy: 28.09\n",
      "Mini-batch train at step 500 with loss: 15.597188949584961\n",
      "Mini-batch train accuracy: 71.875, valid accuracy: 80.7\n",
      "Mini-batch train at step 1000 with loss: 5.954239845275879\n",
      "Mini-batch train accuracy: 84.375, valid accuracy: 81.15\n",
      "Mini-batch train at step 1500 with loss: 2.924823760986328\n",
      "Mini-batch train accuracy: 82.8125, valid accuracy: 79.22\n",
      "Mini-batch train at step 2000 with loss: 2.204730749130249\n",
      "Mini-batch train accuracy: 91.40625, valid accuracy: 79.37\n",
      "Mini-batch train at step 2500 with loss: 9.596665382385254\n",
      "Mini-batch train accuracy: 76.5625, valid accuracy: 82.3\n",
      "Mini-batch train at step 3000 with loss: 2.9803805351257324\n",
      "Mini-batch train accuracy: 77.34375, valid accuracy: 82.5\n",
      "Mini-batch train at step 3500 with loss: 4.401630878448486\n",
      "Mini-batch train accuracy: 86.71875, valid accuracy: 82.4\n",
      "Mini-batch train at step 4000 with loss: 1.2764641046524048\n",
      "Mini-batch train accuracy: 85.9375, valid accuracy: 82.54\n",
      "Mini-batch train at step 4500 with loss: 2.8722896575927734\n",
      "Mini-batch train accuracy: 82.03125, valid accuracy: 82.32\n",
      "Mini-batch train at step 5000 with loss: 2.195223569869995\n",
      "Mini-batch train accuracy: 83.59375, valid accuracy: 83.5\n",
      "Mini-batch train at step 5500 with loss: 1.370304822921753\n",
      "Mini-batch train accuracy: 89.0625, valid accuracy: 83.62\n",
      "Mini-batch train at step 6000 with loss: 3.0299835205078125\n",
      "Mini-batch train accuracy: 85.15625, valid accuracy: 83.5\n",
      "Mini-batch train at step 6500 with loss: 1.9944888353347778\n",
      "Mini-batch train accuracy: 85.9375, valid accuracy: 83.78\n",
      "Mini-batch train at step 7000 with loss: 1.4375073909759521\n",
      "Mini-batch train accuracy: 82.03125, valid accuracy: 84.13\n",
      "Mini-batch train at step 7500 with loss: 2.518005132675171\n",
      "Mini-batch train accuracy: 90.625, valid accuracy: 83.65\n",
      "Mini-batch train at step 8000 with loss: 0.6734506487846375\n",
      "Mini-batch train accuracy: 89.0625, valid accuracy: 84.05\n",
      "Mini-batch train at step 8500 with loss: 1.2857871055603027\n",
      "Mini-batch train accuracy: 89.0625, valid accuracy: 84.15\n",
      "Mini-batch train at step 9000 with loss: 0.7839235663414001\n",
      "Mini-batch train accuracy: 86.71875, valid accuracy: 84.28\n",
      "Mini-batch train at step 9500 with loss: 0.9161803722381592\n",
      "Mini-batch train accuracy: 85.15625, valid accuracy: 84.7\n",
      "Mini-batch train at step 10000 with loss: 2.769279718399048\n",
      "Mini-batch train accuracy: 82.8125, valid accuracy: 84.73\n",
      "Mini-batch train at step 10500 with loss: 1.458433747291565\n",
      "Mini-batch train accuracy: 87.5, valid accuracy: 83.9\n",
      "Mini-batch train at step 11000 with loss: 0.29847702383995056\n",
      "Mini-batch train accuracy: 90.625, valid accuracy: 84.93\n",
      "Mini-batch train at step 11500 with loss: 0.40550482273101807\n",
      "Mini-batch train accuracy: 88.28125, valid accuracy: 84.54\n",
      "Mini-batch train at step 12000 with loss: 0.341203898191452\n",
      "Mini-batch train accuracy: 93.75, valid accuracy: 85.63\n",
      "Mini-batch train at step 12500 with loss: 1.697537899017334\n",
      "Mini-batch train accuracy: 89.84375, valid accuracy: 85.06\n",
      "Mini-batch train at step 13000 with loss: 1.0425019264221191\n",
      "Mini-batch train accuracy: 91.40625, valid accuracy: 84.85\n",
      "Mini-batch train at step 13500 with loss: 1.0025322437286377\n",
      "Mini-batch train accuracy: 86.71875, valid accuracy: 84.72\n",
      "Mini-batch train at step 14000 with loss: 0.31426626443862915\n",
      "Mini-batch train accuracy: 91.40625, valid accuracy: 85.19\n",
      "Mini-batch train at step 14500 with loss: 0.32025057077407837\n",
      "Mini-batch train accuracy: 92.1875, valid accuracy: 84.76\n",
      "Mini-batch train at step 15000 with loss: 0.5186724066734314\n",
      "Mini-batch train accuracy: 90.625, valid accuracy: 85.05\n",
      "Mini-batch train at step 15500 with loss: 0.7220499515533447\n",
      "Mini-batch train accuracy: 88.28125, valid accuracy: 85.24\n",
      "Mini-batch train at step 16000 with loss: 0.45146945118904114\n",
      "Mini-batch train accuracy: 88.28125, valid accuracy: 85.14\n",
      "Mini-batch train at step 16500 with loss: 0.19604039192199707\n",
      "Mini-batch train accuracy: 94.53125, valid accuracy: 85.25\n",
      "Mini-batch train at step 17000 with loss: 0.867277979850769\n",
      "Mini-batch train accuracy: 85.9375, valid accuracy: 85.23\n",
      "Mini-batch train at step 17500 with loss: 0.24928395450115204\n",
      "Mini-batch train accuracy: 92.1875, valid accuracy: 85.1\n",
      "Mini-batch train at step 18000 with loss: 0.6595797538757324\n",
      "Mini-batch train accuracy: 88.28125, valid accuracy: 85.04\n",
      "Mini-batch train at step 18500 with loss: 0.3000246286392212\n",
      "Mini-batch train accuracy: 91.40625, valid accuracy: 85.22\n",
      "Mini-batch train at step 19000 with loss: 0.33893755078315735\n",
      "Mini-batch train accuracy: 91.40625, valid accuracy: 85.81\n",
      "Mini-batch train at step 19500 with loss: 0.2945917844772339\n",
      "Mini-batch train accuracy: 92.96875, valid accuracy: 85.7\n",
      "Mini-batch train at step 20000 with loss: 0.20481166243553162\n",
      "Mini-batch train accuracy: 92.96875, valid accuracy: 85.56\n",
      "Mini-batch train at step 20500 with loss: 0.2757508456707001\n",
      "Mini-batch train accuracy: 94.53125, valid accuracy: 85.75\n",
      "Mini-batch train at step 21000 with loss: 1.1255435943603516\n",
      "Mini-batch train accuracy: 93.75, valid accuracy: 85.53\n",
      "Mini-batch train at step 21500 with loss: 0.4262843132019043\n",
      "Mini-batch train accuracy: 96.09375, valid accuracy: 86.29\n",
      "Mini-batch train at step 22000 with loss: 0.5938369035720825\n",
      "Mini-batch train accuracy: 93.75, valid accuracy: 85.97\n",
      "Mini-batch train at step 22500 with loss: 0.2699505090713501\n",
      "Mini-batch train accuracy: 95.3125, valid accuracy: 86.33\n",
      "Mini-batch train at step 23000 with loss: 0.27653950452804565\n",
      "Mini-batch train accuracy: 92.1875, valid accuracy: 85.88\n",
      "Mini-batch train at step 23500 with loss: 0.3027464747428894\n",
      "Mini-batch train accuracy: 93.75, valid accuracy: 86.24\n",
      "Mini-batch train at step 24000 with loss: 0.1711682379245758\n",
      "Mini-batch train accuracy: 95.3125, valid accuracy: 86.03\n",
      "Mini-batch train at step 24500 with loss: 0.23012250661849976\n",
      "Mini-batch train accuracy: 91.40625, valid accuracy: 86.38\n",
      "Mini-batch train at step 25000 with loss: 0.13898806273937225\n",
      "Mini-batch train accuracy: 95.3125, valid accuracy: 86.41\n",
      "Mini-batch train at step 25500 with loss: 1.170966386795044\n",
      "Mini-batch train accuracy: 91.40625, valid accuracy: 86.35\n",
      "Mini-batch train at step 26000 with loss: 0.17182238399982452\n",
      "Mini-batch train accuracy: 93.75, valid accuracy: 86.1\n",
      "Mini-batch train at step 26500 with loss: 0.2070501148700714\n",
      "Mini-batch train accuracy: 93.75, valid accuracy: 86.62\n",
      "Mini-batch train at step 27000 with loss: 0.1615358293056488\n",
      "Mini-batch train accuracy: 93.75, valid accuracy: 86.39\n",
      "Mini-batch train at step 27500 with loss: 0.28023844957351685\n",
      "Mini-batch train accuracy: 96.09375, valid accuracy: 86.47\n",
      "Mini-batch train at step 28000 with loss: 0.3365170955657959\n",
      "Mini-batch train accuracy: 95.3125, valid accuracy: 86.48\n",
      "Mini-batch train at step 28500 with loss: 0.09492664784193039\n",
      "Mini-batch train accuracy: 95.3125, valid accuracy: 86.55\n",
      "Mini-batch train at step 29000 with loss: 0.22823016345500946\n",
      "Mini-batch train accuracy: 94.53125, valid accuracy: 86.46\n",
      "Mini-batch train at step 29500 with loss: 0.2783079147338867\n",
      "Mini-batch train accuracy: 90.625, valid accuracy: 86.25\n",
      "Mini-batch train at step 30000 with loss: 0.09588967263698578\n",
      "Mini-batch train accuracy: 96.09375, valid accuracy: 86.72\n",
      "Mini-batch test accuarcy: 92.31\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initilazed')\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        offset = (step*batch_size)%(train_labels.shape[0]-batch_size)\n",
    "        # generate a mini-batch\n",
    "        batch_data = train_data[offset:(offset+batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "        \n",
    "        # dict to feed mini-batch\n",
    "        feed_dict = {tf_train_data: batch_data, tf_train_labels: batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        \n",
    "        # logging\n",
    "        if step % 500 == 0:\n",
    "            print('Mini-batch train at step {} with loss: {}'.format(step, l))\n",
    "            print('Mini-batch train accuracy: {}, valid accuracy: {}'.format(\n",
    "                 accuracy(predictions, batch_labels),\n",
    "                 accuracy(valid_prediction.eval(), valid_labels)))\n",
    "    print('Mini-batch test accuarcy: {}'.format(accuracy(test_prediction.eval(), test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
