{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from hanziconv import HanziConv\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\7153678\\Desktop\\AI\\src\\nlp\\data\\datasource-master\\movie_comments.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (0,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "comment = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                        link name  \\\n",
       "0  1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1  2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1  \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49355</th>\n",
       "      <td>48008</td>\n",
       "      <td>https://movie.douban.com/subject/1291824/</td>\n",
       "      <td>黑鹰坠落 Black Hawk Down</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49364</th>\n",
       "      <td>48017</td>\n",
       "      <td>https://movie.douban.com/subject/1291824/</td>\n",
       "      <td>黑鹰坠落 Black Hawk Down</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                       link                  name  \\\n",
       "49355  48008  https://movie.douban.com/subject/1291824/  黑鹰坠落 Black Hawk Down   \n",
       "49364  48017  https://movie.douban.com/subject/1291824/  黑鹰坠落 Black Hawk Down   \n",
       "\n",
       "      comment star  \n",
       "49355     NaN    3  \n",
       "49364     NaN    3  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_index = comment[comment['comment'].isnull()].index\n",
    "comment.loc[null_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "link       0\n",
       "name       0\n",
       "comment    0\n",
       "star       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comment.drop(null_index,inplace=True)\n",
    "comment.dropna(inplace=True)\n",
    "comment.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_path = r'C:\\Users\\7153678\\Desktop\\AI\\src\\nlp\\data\\stopword.txt'\n",
    "stops = set()\n",
    "with open(stop_words_path, 'r', encoding='utf8') as rf:\n",
    "    for line in rf:\n",
    "        stops.add(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_hanzi_contained(ss):\n",
    "    pattern = re.compile(r'[\\u4E00-\\u9FA5]')\n",
    "    if pattern.findall(ss):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def convert_to_simplified(ss):\n",
    "    return HanziConv.toSimplified(ss)\n",
    "    \n",
    "def cut(ss):\n",
    "    cuts = ''.join(re.findall(r'\\w+', ss))\n",
    "    return jieba.cut(cuts)\n",
    "    \n",
    "def clear_web_chars(ss, webs=r'\\\\n|&nbsp|\\xa0|\\\\xa0|\\u3000|\\\\u3000|\\\\u0020|\\u0020'):\n",
    "    return re.sub(webs, '', ss)\n",
    "\n",
    "def clear_stop_words(ss, stops):\n",
    "    return [s for s in ss if s not in stops]\n",
    "    \n",
    "def get_cut_hz(ss):\n",
    "    ss = convert_to_simplified(ss)\n",
    "    ss = clear_web_chars(ss)\n",
    "    ss = list(cut(ss))\n",
    "#     ss = clear_stop_words(ss, stops)\n",
    "    if is_hanzi_contained(''.join(ss)):\n",
    "        return (ss)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment['words'] = comment['comment'].apply(get_cut_hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 12038,\n",
       "         '1': 12083,\n",
       "         2: 13517,\n",
       "         '2': 14059,\n",
       "         3: 32851,\n",
       "         '3': 30949,\n",
       "         4: 41419,\n",
       "         '4': 39578,\n",
       "         '5': 30691,\n",
       "         5: 26151})"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(comment['star'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment.drop(comment[comment['star']=='star'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    80997\n",
      "3    63800\n",
      "5    56842\n",
      "2    27576\n",
      "1    24121\n",
      "Name: star, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b3acbe5cf8>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comment['star'] = pd.to_numeric(comment['star'])\n",
    "star_count = comment['star'].value_counts()\n",
    "print(star_count)\n",
    "star_count.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = [word for word, count in mini_counter.items() if count < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_corpus_w2v_path = os.path.join(os.path.dirname(file_path), 'movie_corpus_w2v.txt')\n",
    "with open(movie_corpus_w2v_path, 'w', encoding='utf-8') as wf:\n",
    "    for words in comment['words']:\n",
    "        try:\n",
    "            wf.write(' '.join(words) + '\\n')   \n",
    "        except:\n",
    "            print(words)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "w2v_model_path = r'C:\\Users\\7153678\\Desktop\\AI\\src\\nlp\\model\\word2vec\\word2vec_wiki.model'  # word2vec模型目录的路径, trained by wiki\n",
    "model = Word2Vec.load(w2v_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "sentences = LineSentence(movie_corpus_w2v_path)\n",
    "model.train(sentences,total_examples=comment.shape[0], epochs=5)\n",
    "new_model_path = os.path.join(os.path.dirname(w2v_model_path), 'movie_corpus_w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_words = list(chain.from_iterable(comment['words'].tolist()))   \n",
    "comment_tf = Counter(comment_words)\n",
    "with open(comment_tf_path, 'wb') as wf:\n",
    "    pickle.dump(comment_tf, wf, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_wiki_path = os.path.join(os.path.dirname(movie_corpus_w2v_path), 'wiki_tf.pickle')\n",
    "with open(comment_wiki_path, 'rb') as rf:\n",
    "    wiki_tf = pickle.load(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in comment_tf:\n",
    "    wiki_tf[word] += comment_tf[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_path = os.path.join(os.path.dirname(movie_corpus_w2v_path), 'tf.pickle')\n",
    "with open(tf_path, 'wb') as wf:\n",
    "    pickle.dump(wiki_tf, wf, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = wiki_tf\n",
    "sentences = comment['words'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vector(sentences, w2v_model, tf, a=1e-3, npc=1):\n",
    "    s2v = np.zeros([len(sentences), w2v_model.vector_size])\n",
    "    invalid_indecis = list()\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        w2v = np.zeros(w2v_model.vector_size)\n",
    "        j = 0\n",
    "        for j, word in enumerate(sentence):\n",
    "            if word in w2v_model.wv.vocab and word in tf:\n",
    "                weight = a/(a+tf[word])\n",
    "                w2v += w2v_model[word]*weight\n",
    "                j += 1\n",
    "        if j == 0:\n",
    "#             print('Invalid index: {}, sentence: {}'.format(i, sentence)) \n",
    "            invalid_indecis.append(i)\n",
    "            continue\n",
    "        s2v[i,:] = w2v/j\n",
    "    \n",
    "    return s2v, invalid_indecis\n",
    "\n",
    "def remove_pc(s2v, npc=1):\n",
    "    svd = TruncatedSVD(n_components=npc, n_iter=7, random_state=0)\n",
    "    svd.fit(s2v)\n",
    "    u = svd.components_\n",
    "    s2v = s2v - s2v.dot(u.T).dot(u)\n",
    "    \n",
    "    return s2v    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "s2v, indecis = sentence_to_vector(sentences, model, tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_final = comment.reset_index().drop(indecis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2v_final = np.delete(s2v, indecis, axis=0)\n",
    "s2v_final = remove_pc(s2v_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_final = np.array(comment_final['star'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((251842, 7), (251842, 200), (251842,))"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_final.shape, s2v_final.shape, star_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    80650\n",
      "3    63400\n",
      "5    56468\n",
      "2    27380\n",
      "1    23944\n",
      "Name: star, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b44b13c6d8>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "star_count = comment_final['star'].value_counts()\n",
    "print(star_count)\n",
    "star_count.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((251842, 200), (251842,))"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = s2v_final\n",
    "labels = star_final\n",
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (203991, 200) and (203991,)\n",
      "valid: (22666, 200) and (22666,)\n",
      "test: (25185, 200) and (25185,)\n"
     ]
    }
   ],
   "source": [
    "train_valid_data, test_data, train_valid_labels, test_labels = train_test_split(data, labels, test_size=0.1,random_state=42)\n",
    "train_data, valid_data, train_labels, valid_labels = train_test_split(train_valid_data, train_valid_labels, test_size=0.1,random_state=42)\n",
    "print('train: {} and {}'.format(train_data.shape, train_labels.shape))\n",
    "print('valid: {} and {}'.format(valid_data.shape, valid_labels.shape))    \n",
    "print('test: {} and {}'.format(test_data.shape, test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (203991, 200) and (203991, 5)\n",
      "valid: (22666, 200) and (22666, 5)\n",
      "test: (25185, 200) and (25185, 5)\n"
     ]
    }
   ],
   "source": [
    "def reformat(data, labels):\n",
    "    new_data = data\n",
    "    new_label = (labels[:, None] == np.arange(1, class_num+1)).astype(np.float64)\n",
    "    return new_data, new_label\n",
    "\n",
    "\n",
    "train_data, train_labels = reformat(train_data, train_labels)\n",
    "valid_data, valid_labels = reformat(valid_data, valid_labels)\n",
    "test_data, test_labels = reformat(test_data, test_labels)\n",
    "print('train: {} and {}'.format(train_data.shape, train_labels.shape))\n",
    "print('valid: {} and {}'.format(valid_data.shape, valid_labels.shape))    \n",
    "print('test: {} and {}'.format(test_data.shape, test_labels.shape))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return 100.0*sum(np.argmax(predictions, 1)==np.argmax(labels, 1))/labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "feature_size = test_data.shape[1]\n",
    "h1 = 200\n",
    "beta = 0.01\n",
    "num_steps = 30001\n",
    "learn_rate = 0.01\n",
    "keep_prob = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initilazed\n",
      "Mini-batch train at step 0 with loss: 158.63017619432767\n",
      "Mini-batch train accuracy: 16.40625, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 1000 with loss: 129.994156880747\n",
      "Mini-batch train accuracy: 38.28125, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 2000 with loss: 106.7578522970349\n",
      "Mini-batch train accuracy: 36.71875, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 3000 with loss: 87.66189409088584\n",
      "Mini-batch train accuracy: 32.03125, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 4000 with loss: 72.07949296321549\n",
      "Mini-batch train accuracy: 30.46875, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 5000 with loss: 59.28705184453149\n",
      "Mini-batch train accuracy: 32.03125, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 6000 with loss: 48.78717658304299\n",
      "Mini-batch train accuracy: 32.8125, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 7000 with loss: 40.1921776359578\n",
      "Mini-batch train accuracy: 38.28125, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 8000 with loss: 33.1941862635557\n",
      "Mini-batch train accuracy: 32.03125, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 9000 with loss: 27.42682529232823\n",
      "Mini-batch train accuracy: 35.9375, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 10000 with loss: 22.753898728236308\n",
      "Mini-batch train accuracy: 28.125, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 11000 with loss: 18.910538674224004\n",
      "Mini-batch train accuracy: 35.15625, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 12000 with loss: 15.748327246174254\n",
      "Mini-batch train accuracy: 29.6875, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 13000 with loss: 13.1890508174727\n",
      "Mini-batch train accuracy: 24.21875, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 14000 with loss: 11.026064485367364\n",
      "Mini-batch train accuracy: 32.03125, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 15000 with loss: 9.321153017254238\n",
      "Mini-batch train accuracy: 35.9375, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 16000 with loss: 7.851663890066098\n",
      "Mini-batch train accuracy: 35.9375, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 17000 with loss: 6.743978424422719\n",
      "Mini-batch train accuracy: 32.8125, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 18000 with loss: 5.869585789772721\n",
      "Mini-batch train accuracy: 32.03125, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 19000 with loss: 5.086574800647378\n",
      "Mini-batch train accuracy: 27.34375, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 20000 with loss: 4.394097669671189\n",
      "Mini-batch train accuracy: 32.03125, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 21000 with loss: 3.836236156648215\n",
      "Mini-batch train accuracy: 33.59375, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 22000 with loss: 3.3544709696954236\n",
      "Mini-batch train accuracy: 35.9375, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 23000 with loss: 3.108707459126722\n",
      "Mini-batch train accuracy: 27.34375, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 24000 with loss: 2.7991361265993726\n",
      "Mini-batch train accuracy: 30.46875, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 25000 with loss: 2.5215225198369104\n",
      "Mini-batch train accuracy: 30.46875, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 26000 with loss: 2.418298033066299\n",
      "Mini-batch train accuracy: 30.46875, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 27000 with loss: 2.248066126233659\n",
      "Mini-batch train accuracy: 37.5, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 28000 with loss: 2.090434507822622\n",
      "Mini-batch train accuracy: 32.03125, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 29000 with loss: 1.9862575690381052\n",
      "Mini-batch train accuracy: 34.375, valid accuracy: 31.81417100502956\n",
      "Mini-batch train at step 30000 with loss: 1.9552740690523218\n",
      "Mini-batch train accuracy: 28.125, valid accuracy: 31.81417100502956\n",
      "Mini-batch test accuarcy: 32.189795513202306\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    # input, only train is with SGD\n",
    "    tf_train_data = tf.placeholder(tf.float64, shape=(batch_size, feature_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float64, shape=(batch_size, class_num))\n",
    "    tf_valid_data = tf.constant(valid_data)\n",
    "    tf_test_data = tf.constant(test_data)\n",
    "    \n",
    "    # variables\n",
    "    weights1 = tf.Variable(tf.truncated_normal([feature_size, h1], dtype=np.float64))\n",
    "    biases1 = tf.Variable(tf.zeros(h1, dtype=np.float64))  \n",
    "    weights2 = tf.Variable(tf.truncated_normal([h1, class_num], dtype=np.float64))\n",
    "    biases2 = tf.Variable(tf.zeros(class_num, dtype=np.float64))  \n",
    "    \n",
    "    # train compution   \n",
    "    logits_1 = tf.matmul(tf_train_data, weights1) + biases1\n",
    "    relu_layer = tf.nn.relu(logits_1)\n",
    "    dropout_layer = tf.nn.dropout(relu_layer, keep_prob=keep_prob)\n",
    "    logits_2 = tf.matmul(dropout_layer, weights2) + biases2\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels, logits=logits_2))\n",
    "    regularization = beta*(tf.nn.l2_loss(weights1) + tf.nn.l2_loss(biases1) + tf.nn.l2_loss(weights2) + tf.nn.l2_loss(biases2))\n",
    "    loss = tf.reduce_mean(loss + regularization)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learn_rate).minimize(loss)\n",
    "    \n",
    "    # prediction\n",
    "    train_prediction = tf.nn.softmax(logits_2)\n",
    "    \n",
    "    logits_1 = tf.matmul(tf_valid_data, weights1) + biases1\n",
    "    relu_layer = tf.nn.relu(logits_1)\n",
    "    logits_2 = tf.matmul(relu_layer, weights2) + biases2\n",
    "    valid_prediction = tf.nn.softmax(logits_2)\n",
    "\n",
    "    logits_1 = tf.matmul(tf_test_data, weights1) + biases1\n",
    "    relu_layer = tf.nn.relu(logits_1)\n",
    "    logits_2 = tf.matmul(relu_layer, weights2) + biases2\n",
    "    test_prediction = tf.nn.softmax(logits_2)\n",
    "    \n",
    "with tf.Session(graph=g) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initilazed')\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        offset = (step*batch_size)%(train_labels.shape[0]-batch_size)\n",
    "        # generate a mini-batch\n",
    "        batch_data = train_data[offset:(offset+batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "        \n",
    "        # dict to feed mini-batch\n",
    "        feed_dict = {tf_train_data: batch_data, tf_train_labels: batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        \n",
    "        # logging\n",
    "        if step % 1000 == 0:\n",
    "            print('Mini-batch train at step {} with loss: {}'.format(step, l))\n",
    "            print('Mini-batch train accuracy: {}, valid accuracy: {}'.format(\n",
    "                 accuracy(predictions, batch_labels),\n",
    "                 accuracy(valid_prediction.eval(), valid_labels)))\n",
    "    print('Mini-batch test accuarcy: {}'.format(accuracy(test_prediction.eval(), test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    '''Model function of CNN'''\n",
    "    \n",
    "    # Input layer\n",
    "    input_layer = tf.reshape(features['x'], [-1, 10, 20, 1])\n",
    "    print(input_layer.shape)\n",
    "    \n",
    "    # Convolutional layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs = input_layer, \n",
    "        filters=32,\n",
    "        kernel_size=[5, 5], \n",
    "        padding='same', \n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # Pooling layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # Convolutional layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1, \n",
    "        filters=64, \n",
    "        kernel_size=[5, 5], \n",
    "        padding='same', \n",
    "        activation=tf.nn.relu)\n",
    "      \n",
    "    # Pooling layer #1\n",
    "#     pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # Dense layer #1\n",
    "    pool2_flat = tf.reshape(conv2, [-1, 5*10*64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.4, \n",
    "                                training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    #Logits layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=class_num)\n",
    "    \n",
    "    predictions = {\n",
    "        'classes': tf.argmax(input=logits, axis=1),\n",
    "        'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    # Loss\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits))\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05)\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "        \n",
    "    eval_metric_ops = {\n",
    "        'accuracy': tf.metrics.accuracy(labels=tf.argmax(input=labels, axis=1),\n",
    "                                        predictions=predictions['classes'])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode=mode,loss=loss,\n",
    "                                      eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_num_ps_replicas': 0, '_is_chief': True, '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002B3D0923470>, '_session_config': None, '_task_id': 0, '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_tf_random_seed': None, '_train_distribute': None, '_device_fn': None, '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_master': '', '_save_checkpoints_steps': None, '_evaluation_master': '', '_num_worker_replicas': 1, '_model_dir': 'C:\\\\Users\\\\7153678\\\\Desktop\\\\AI\\\\src\\\\nlp\\\\homework\\\\lesson10', '_save_checkpoints_secs': 600, '_service': None}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "data_root = r'C:\\Users\\7153678\\Desktop\\AI\\src\\nlp\\homework\\lesson10'\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "(100, 10, 20, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension size must be evenly divisible by 3136 but is 64000 for 'Reshape_1' (op: 'Reshape') with input shapes: [100,2,5,64], [2] and with input tensors computed as partial shapes: input[1] = [?,3136].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1575\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1576\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1577\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimension size must be evenly divisible by 3136 but is 64000 for 'Reshape_1' (op: 'Reshape') with input shapes: [100,2,5,64], [2] and with input tensors computed as partial shapes: input[1] = [?,3136].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-390-b0808c0af84d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     hooks=[logging_hook])\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1143\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1168\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m-> 1170\u001b[1;33m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[0;32m   1171\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1172\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-386-af07876bdb50>\u001b[0m in \u001b[0;36mcnn_model_fn\u001b[1;34m(features, labels, mode)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Dense layer #1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mpool2_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mdense\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpool2_flat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     dropout = tf.layers.dropout(inputs=dense, rate=0.4, \n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   6196\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6197\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 6198\u001b[1;33m         \"Reshape\", tensor=tensor, shape=shape, name=name)\n\u001b[0m\u001b[0;32m   6199\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6200\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                 instructions)\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3153\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3154\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3155\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3156\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3157\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1729\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1730\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1731\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1577\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1579\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension size must be evenly divisible by 3136 but is 64000 for 'Reshape_1' (op: 'Reshape') with input shapes: [100,2,5,64], [2] and with input tensors computed as partial shapes: input[1] = [?,3136]."
     ]
    }
   ],
   "source": [
    "# train one step and display the probabilties\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": test_data},\n",
    "    y=test_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "test_results = mnist_classifier.evaluate(input_fn=test_input_fn)\n",
    "print(test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
